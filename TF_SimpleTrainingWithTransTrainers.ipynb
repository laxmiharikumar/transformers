{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMz8KSr5OyYzyYqRpIyY0Uy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laxmiharikumar/transformers/blob/main/TF_SimpleTrainingWithTransTrainers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "hZk5SV1RDvJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLvjj7LVP7qY"
      },
      "outputs": [],
      "source": [
        "! pip install transformers datasets --quiet --upgrade "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset emotion"
      ],
      "metadata": {
        "id": "XwFutiWOSZgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "emotion_dataset = load_dataset(\"emotion\")\n",
        "emotion_dataset"
      ],
      "metadata": {
        "id": "RkWNkLmQTaGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dataset[\"train\"][\"text\"][23]"
      ],
      "metadata": {
        "id": "p3pd0pkiUB-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## While visualizing and exploring the dataset it is better to use pandas\n",
        "emotion_df = emotion_dataset[\"train\"].to_pandas()\n",
        "emotion_df"
      ],
      "metadata": {
        "id": "b4zMoOC8UJ3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understand what the labels are\n",
        "features = emotion_dataset[\"train\"].features\n",
        "features"
      ],
      "metadata": {
        "id": "VSEzBrLMWsEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features[\"label\"].int2str(3)"
      ],
      "metadata": {
        "id": "rxvrt3ILXJlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an id to label dictionary\n",
        "id2label = {idx:features[\"label\"].int2str(idx) for idx in range(6)}\n",
        "id2label"
      ],
      "metadata": {
        "id": "m2Qx8N1xXrCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a label to id dictionary\n",
        "label2id = {value:key for key,value in id2label.items()}\n",
        "label2id"
      ],
      "metadata": {
        "id": "lMQR5WipYYyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Check how many you have in each label category\n",
        "emotion_df[\"label\"].value_counts(normalize=True).sort_index()"
      ],
      "metadata": {
        "id": "O6120l3RYsdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels are very imbalanced. 30% is sadness. 3% only for suprprise. If the train the model naively on this distribution, one problem that can happen is tthe model will get very good at predicting these majority classes but struggle a lot of these rare classes.\n",
        "We can up sample the rare classes i.e duplicate the rare classes until we get an even distribution. But the problem is that deep learning models liek transformers are really good at memorizing or discovering patterns in the data and so if we duplicate a lot of examples then probably the model is going to kind of memorize those duplicates and when it sees examples from that class in production it is not going to generalize very well.\n",
        "So we are going to modify the loss function of the model during training and this will allow us to introduce a bias directly at the level of loss function which indicates these are the ways that the classes are distributed and hopefully this will encourage the model to pay more attention to these rare classes"
      ],
      "metadata": {
        "id": "vcikxjTRZeDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "\n",
        "MiniLM is smaller than BERT but just 1% lower in accuracy. Better to start off with such models. We can iterate faster"
      ],
      "metadata": {
        "id": "46OyysRHf4_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"microsoft/MiniLM-L12-H384-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint, return_tensors=\"tf\") "
      ],
      "metadata": {
        "id": "Ds_614fLf7Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dataset[\"train\"][\"text\"][:1]"
      ],
      "metadata": {
        "id": "jZf5tNMZhEfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed in an example\n",
        "tokenizer(emotion_dataset[\"train\"][\"text\"][:1])"
      ],
      "metadata": {
        "id": "RQJ6oRIDg5GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "input_ids - tokenized inputs that we are feeding to the model\n",
        "token_type_ids - to indicate if sentence 1 or sentence 2\n",
        "attention_mask - to indicate which tokens correspond to padding or not"
      ],
      "metadata": {
        "id": "1t_0FE5xioAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply this tokenizer to all the examples in the dataset\n",
        "def tokenize_text(examples):\n",
        "  return tokenizer(examples[\"text\"], truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "wKp091_EjePz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dataset = emotion_dataset.map(tokenize_text, batched=True)\n",
        "emotion_dataset"
      ],
      "metadata": {
        "id": "EO01GYMDj1vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with imbalanced data\n",
        "\n",
        "In the data there is some frequency distribution and we are going to introduce some weights/coefficients for the loss function which will multiply each one of those classes by an amount that is reflected in the data. If we demand that these coefficients range from 0 to 1, assign a high weight to rare classes and low weight to common classes so that the model doesnt get too biased on the majority classes"
      ],
      "metadata": {
        "id": "WhhWO8fmkhmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(emotion_df) # This is the training dataset"
      ],
      "metadata": {
        "id": "C2e9BKTsoKRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_weights = (1 - (emotion_df[\"label\"].value_counts().sort_index() / len(emotion_df))).values\n",
        "tmp_weights, type(tmp_weights)"
      ],
      "metadata": {
        "id": "MCcPWcyxn2eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We want all the weights to be dictionary as we are working with tf\n",
        "\n",
        "class_weights = {idx:tmp_weights[idx] for idx in range(len(tmp_weights))}\n",
        "class_weights"
      ],
      "metadata": {
        "id": "qOMxItDrpIH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Rename label colum to labels\n",
        "emotion_dataset = emotion_dataset.rename_column(\"label\", \"labels\")\n",
        "emotion_dataset"
      ],
      "metadata": {
        "id": "JN4dOJEK5EAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ],
      "metadata": {
        "id": "EQ7tu5MG_I_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint,\n",
        "                                                           num_labels=6,\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id,\n",
        "                                                           from_pt=True)"
      ],
      "metadata": {
        "id": "yR3vBy21_Ll5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = val_labels\n",
        "  preds = np.argmax(tf.squeeze(pred[0]), axis=1)\n",
        "  f1 = metrics.f1_score(labels, preds, average=\"weighted\")\n",
        "  return {\"f1\": f1}"
      ],
      "metadata": {
        "id": "4ggQDDBT_sN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "tGa_tuGBPPhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_dataset = emotion_dataset[\"train\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "tf_validation_dataset = emotion_dataset[\"validation\"].to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "id": "coQJWIcbPr4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_dataset[\"validation\"][\"labels\"][:10]"
      ],
      "metadata": {
        "id": "n53_obKhRFFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "val_labels = np.concatenate([y for x, y in tf_validation_dataset], axis=0)\n",
        "val_labels[:10]"
      ],
      "metadata": {
        "id": "-9eXNgbXPkou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
        "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
        "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
        "num_train_steps = len(tf_train_dataset) * num_epochs\n",
        "lr_scheduler = PolynomialDecay(\n",
        "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
        ")\n",
        "\n",
        "opt = Adam(learning_rate=lr_scheduler)"
      ],
      "metadata": {
        "id": "b4tkdU_aHY79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "z_bXkUT5QRjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "6e-pcfpmCfIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.keras_callbacks import PushToHubCallback, KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_dataset)\n",
        "push_to_hub_callback = PushToHubCallback(\n",
        "    output_dir=\"./minilm-finetuned-emotion\", tokenizer=tokenizer, hub_model_id=\"laxsvips/minilm-finetuned-emotion\"\n",
        ")"
      ],
      "metadata": {
        "id": "QVHdgaLjAVNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model.fit(\n",
        "    tf_train_dataset,\n",
        "    validation_data=tf_validation_dataset,\n",
        "    epochs=num_epochs,\n",
        "    class_weight=class_weights,\n",
        "    callbacks= [push_to_hub_callback, metric_callback]\n",
        "    )"
      ],
      "metadata": {
        "id": "Ig53GU-NQoL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training data separately\n",
        "from matplotlib import pyplot as plt\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "BB4T2eXTEVBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy\n",
        "plot_loss_curves(history_1)"
      ],
      "metadata": {
        "id": "jFezKbSGE60V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(tf_validation_dataset)"
      ],
      "metadata": {
        "id": "nIViP2JCG7vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pred_probs = model.predict(tf_validation_dataset)\n",
        "model_pred_probs[:10]"
      ],
      "metadata": {
        "id": "4VFZLhWAHG5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pred_probs[0][3]"
      ],
      "metadata": {
        "id": "q7CyNQapIZ9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.squeeze(model_pred_probs[0])\n",
        "np.argmax(a[3])"
      ],
      "metadata": {
        "id": "eZSKdXiOI1hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "model_preds = np.argmax(tf.squeeze(model_pred_probs[0]), axis=1)\n",
        "model_preds[:10]"
      ],
      "metadata": {
        "id": "nj3LS26QHRTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = list(tf_validation_dataset)\n",
        "train_data[0]"
      ],
      "metadata": {
        "id": "xuPbkxUXOP-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  eval_metrics = {}\n",
        "  eval_metrics[\"accuracy\"] = metrics.accuracy_score(y_true, y_pred)\n",
        "  eval_metrics[\"precision\"] = metrics.precision_score(y_true, y_pred, average='weighted') # multiclass\n",
        "  eval_metrics[\"recall\"] = metrics.recall_score(y_true, y_pred, average='weighted') # multiclass\n",
        "  eval_metrics[\"f1_score\"] = metrics.f1_score(y_true, y_pred, average='weighted') # multiclass\n",
        "\n",
        "  return eval_metrics"
      ],
      "metadata": {
        "id": "37wPhhJyabxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = calculate_results(val_labels, model_preds)\n",
        "model_results"
      ],
      "metadata": {
        "id": "8SN_b_PgNLXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Use your finetuned model\n",
        "from transformers import pipeline\n",
        "\n",
        "model_cpt = \"laxsvips/minilm-finetuned-emotion\"\n",
        "pipe = pipeline(\"text-classification\", model=model_cpt, return_all_scores=True)"
      ],
      "metadata": {
        "id": "8tSZpwWfHKnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"I am really excited about part 2 of the Hugging Face course\")"
      ],
      "metadata": {
        "id": "OaFJjFCQHS7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_scores = pipe(\"I am so glad you could help me\")\n",
        "predicted_scores"
      ],
      "metadata": {
        "id": "EB_2fGa-Wx1E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}